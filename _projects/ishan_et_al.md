---
authors: ["Ishan Ranjan", "Jack Campbell", "Rani Shah"]
title: VizWiz Visual Question Answering (VQA)
paper_url: /static_files/projects/ranjan_vqa.pdf
video_url: "https://mymedia.bu.edu/media/t/1_cg563hhr"
slides_url: /static_files/projects/ranjan_vqa_preso.pdf
tags: ["Transformer", "LLM", "Vision"]
---

Visual Question Answering (VQA) is a crucial emerging technology that has many real-world
use cases, from assisting those who are visually impaired to providing accurate information
about image features that humans might not be able to discern. To promote the development and
testing of VQA models, VizWiz has formulated a set of challenges to develop models to perform
VQA tasks[3]. We have implemented a multimodal transformer model that accurately predicts
answers to questions about a given set of images. Our model provides a high accuracy of 0.751
as well as an answerability score of 0.798.
